# pyspark-python
## Pyspark 
Apache Spark is written in Scala programming language. PySpark has been released in order to support the collaboration of Apache Spark and Python, it actually is a Python API for Spark. In addition, PySpark, helps you interface with Resilient Distributed Datasets (RDDs) in Apache Spark and Python programming language. This has been achieved by taking advantage of the Py4j library.

## Python 
Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation via the off-side rule. Python is dynamically typed and garbage-collected

### Create Conda Enviroment 
```conda create env_name```

### Activate Conda Enviroment 
```conda activate env_name```

### Install Pyspark  
```conda install -c conda-froge findspark```

```conda install -c conda-froge pyspark```